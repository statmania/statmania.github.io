[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat Mania",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nHyperspectral Imaging Explained\n\n\n5 min\n\n\n\nresearch\n\n\ntechnology\n\n\nimaging\n\n\n\nImagine your eyes (or a regular camera) see the world in only 3 colors: Red, Green, and Blue (RGB). By mixing these, you can create millions of perceived colors, but you‚Ä¶\n\n\n\nAbdullah Al Mahmud\n\n\nJul 24, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Mass Spectrometry Imaging\n\n\n4 min\n\n\n\nresearch\n\n\ntechnology\n\n\nimaging\n\n\n\nImagine you could take a photograph of a slice of tissue, a leaf, or a painting, but instead of seeing colors, you see a map of hundreds of different molecules‚Äîfats‚Ä¶\n\n\n\nAbdullah Al Mahmud\n\n\nJul 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nMicro-XRF: super-powered, non-destructive chemical camera\n\n\n4 min\n\n\n\nresearch\n\n\ntechnology\n\n\nimaging\n\n\n\nMicro-XRF is the super-powered, non-destructive chemical and super-sleuth chemical Camera.\n\n\n\nAbdullah Al Mahmud\n\n\nJul 20, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nInteraction Effect in Regression Analysis\n\n\n3 min\n\n\n\nstatistics\n\n\ntheory\n\n\nregression\n\n\n\nAn interaction effect means the effect of one variable on the outcome depends on the level of another variable.\n\n\n\nAbdullah Al Mahmud\n\n\nNov 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nZ-score: What it is and what it does\n\n\n3 min\n\n\n\nstatistics\n\n\ntheory\n\n\nprobability\n\n\n\nA z-score (also known as a standard score or z-value) measures how many standard deviations a data point is from the mean of a distribution. It‚Äôs a way of‚Ä¶\n\n\n\nAbdullah Al Mahmud\n\n\nNov 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA/B Testing: A Sample Analysis\n\n\n2 min\n\n\n\nstatistics\n\n\ntheory\n\n\nbusiness\n\n\n\nA/B Testing‚Äì A Sample Analysis. Scenario‚Äì Testing a new button color.\n\n\n\nAbdullah Al Mahmud\n\n\nNov 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nIQR in Statistics\n\n\n2 min\n\n\n\nstatistics\n\n\ntheory\n\n\ndispersion\n\n\n\nThe Interquartile Range (IQR) is a measure of statistical dispersion that describes the spread of the middle 50% of data.\n\n\n\nAbdullah Al Mahmud\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nFrom t-test to Anova\n\n\n7 min\n\n\n\nstatistics\n\n\ntheory\n\n\nanova\n\n\n\nLet‚Äôs build this step by step, starting from a t-test and then showing how it generalizes naturally into ANOVA (Analysis of Variance).\n\n\n\nAbdullah Al Mahmud\n\n\nOct 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nARIMA and SARIMA Time Series Models\n\n\n4 min\n\n\n\nstatistics\n\n\ntime-series\n\n\nR\n\n\n\nA clear, concise explanation of ARIMA, SARIMA, and related models ‚Äî followed by minimal R examples..\n\n\n\nAbdullah Al Mahmud\n\n\nOct 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nSpatio-temporal Analysis Workflow\n\n\n2 min\n\n\n\nR\n\n\nGIS\n\n\n\nThe announcement of the clockplot package.\n\n\n\nAbdullah Al Mahmud\n\n\nSep 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclockplot: Plot Event Times on a 24-Hour Clock\n\n\n1 min\n\n\n\nR\n\n\nclockplot\n\n\n\nThe announcement of the clockplot package.\n\n\n\nAbdullah Al Mahmud\n\n\nAug 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nR Package Development Workflow\n\n\n1 min\n\n\n\nR\n\n\npackage\n\n\nprogramming\n\n\n\nThe Workflow that you may follow while developing your own R package.\n\n\n\nAbdullah Al Mahmud\n\n\nAug 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCRAN Package Submission Checklist\n\n\n4 min\n\n\n\nR\n\n\npackage\n\n\nCRAN\n\n\nsubmission\n\n\n\nA comprehensive checklist for a smooth R package submission to CRAN.\n\n\n\nAbdullah Al Mahmud\n\n\nAug 29, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation of an Auto SARIMAX model output in R\n\n\n3 min\n\n\n\nstatistics\n\n\ntime-series\n\n\nR\n\n\n\nA comprehensive explanation of AR (AutoRegressive) and MA (Moving Average) models and their parameters.\n\n\n\nAbdullah Al Mahmud\n\n\nMar 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAutoRegressive and Moving Average Time Series Models with R Code\n\n\n3 min\n\n\n\nstatistics\n\n\ntime-series\n\n\nR\n\n\n\nA comprehensive explanation of AR (AutoRegressive) and MA (Moving Average) models and their parameters.\n\n\n\nAbdullah Al Mahmud\n\n\nFeb 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSARIMAX Time Series Models with R Code\n\n\n5 min\n\n\n\nstatistics\n\n\ntime-series\n\n\nR\n\n\n\nA clear, concise explanation of ARIMA, SARIMA, and related models ‚Äî followed by minimal R examples..\n\n\n\nAbdullah Al Mahmud\n\n\nJan 20, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/r-package-submission.html",
    "href": "posts/r-package-submission.html",
    "title": "CRAN Package Submission Checklist",
    "section": "",
    "text": "Before submitting your R package to CRAN, you should go through a thorough checklist to ensure it meets all the requirements. Failure to meet these standards will result in rejection. The submission process is a manual review, and reviewers are strict about the rules.\n\n\n1. Code Quality and Checks\n\nPass R CMD check --as-cran without any errors, warnings, or notes. This is the most critical step. Run this command from your package‚Äôs root directory. Address every single issue.\nNo Hardcoded Paths: Don‚Äôt use absolute paths like C:/Users/User/my_file.csv. Use system.file() to locate files within your package.\nNo Non-Standard Library Dependencies: Ensure you are not using libraries that are not on CRAN or Bioconductor.\nPackage Size: CRAN has a size limit, which is typically around 5 MB, though larger packages are sometimes accepted if they are well-justified. Use devtools::check_for_size()\n\n\n\n\n2. Documentation and Metadata\n\nDESCRIPTION File: Ensure this file is complete and accurate.\n\nVersion: The version number should be in the format A.B.C (e.g., 1.0.0).\nTitle: This should be concise and capitalized.\nDescription: A detailed, multi-sentence description of what your package does.\nLicense: Specify a valid open-source license, such as MIT or GPL-3.\nURL and BugReports: Include links to your GitHub repository or website.\nImports: List all packages your code uses.\nSuggests: List packages used in examples or vignettes but not essential for core functionality.\n\nman/ Directory: All functions must have a .Rd help file, and all function arguments should be documented. The examples in the help files should be runnable.\nVignettes: Include at least one vignette (.Rmd file in the vignettes/ directory) that provides a user-friendly introduction to your package‚Äôs main features.\nNEWS.md: A file documenting changes between versions is highly recommended.\nREADME File: A comprehensive README.md file in the package‚Äôs root directory is standard practice.\n\n\n\n\n3. User Experience and Best Practices\n\nInformative Error Messages: Your functions should provide clear, user-friendly error messages with stop() and warning() when things go wrong.\nAvoid Namespace Pollution: Use :: to call functions from other packages (e.g., ggplot2::ggplot()) unless a package is attached with library(). This prevents conflicts between functions with the same name.\nMinimal Dependencies: Only import packages you absolutely need to.\nUnit Tests: While not strictly required for a first submission, having a comprehensive suite of unit tests using testthat is highly recommended. They protect against regressions in future versions.\nData: If your package includes data, it should be placed in the data/ directory and documented with a .Rd file.\n\n\n\n\n4. Submission\n\ncran-checks: Check your package against the cran-checks GitHub action if you‚Äôve set it up.\ndevtools::submit_cran(): This function from the devtools package automates much of the submission process, including creating the submission email.\nMaintain Patience: The review process can take anywhere from a few days to several weeks. Be ready to respond to reviewer feedback and make necessary changes.\n\n\n\nHadley Recommendation\nThese are the major steps in the release process:\n\nDetermine the release type, which dictates the version number.\nIf the package is already on CRAN: Do due diligence on existing CRAN results. If this is a first release: confirm you are in compliance with CRAN policies.\nFreshen up documentation files, such as README.md and NEWS.md.\nDouble check() that your package is passing cleanly on multiple operating systems and on the released and development version of R.\nPerform reverse dependency checks, if other packages depend on yours.\nSubmit the package to CRAN and wait for acceptance.\nCreate a GitHub release and prepare for the next version by incrementing the version number.\nPublicize the new version."
  },
  {
    "objectID": "posts/a-b-testing.html",
    "href": "posts/a-b-testing.html",
    "title": "A/B Testing: A Sample Analysis",
    "section": "",
    "text": "A website wants to compare:\n\nVersion A: Blue button\nVersion B: Red button\n\nThe outcome is conversion (1 = user clicked, 0 = did not click)."
  },
  {
    "objectID": "posts/a-b-testing.html#scenario-testing-a-new-button-color",
    "href": "posts/a-b-testing.html#scenario-testing-a-new-button-color",
    "title": "A/B Testing: A Sample Analysis",
    "section": "",
    "text": "A website wants to compare:\n\nVersion A: Blue button\nVersion B: Red button\n\nThe outcome is conversion (1 = user clicked, 0 = did not click)."
  },
  {
    "objectID": "posts/a-b-testing.html#sample-data",
    "href": "posts/a-b-testing.html#sample-data",
    "title": "A/B Testing: A Sample Analysis",
    "section": "Sample data",
    "text": "Sample data\n\nGroup A (blue button)\nUsers: 10 Clicks: 3\nSo conversion rate:\n\\(p_A = \\frac{3}{10} = 0.30\\)\n\n\n\nGroup B (red button)\nUsers: 10 Clicks: 6\nSo conversion rate:\n\\(p_B = \\frac{6}{10} = 0.60\\)"
  },
  {
    "objectID": "posts/a-b-testing.html#step-1-state-hypotheses",
    "href": "posts/a-b-testing.html#step-1-state-hypotheses",
    "title": "A/B Testing: A Sample Analysis",
    "section": "Step 1: State hypotheses",
    "text": "Step 1: State hypotheses\nWe want to know if B performs better than A.\n\\(H_0: p_A = p_B\\) (null hypothesis, which we don‚Äôt expect/want to disprove)\n\\(H_1: p_B &gt; p_A\\) (alternative hypothesis)"
  },
  {
    "objectID": "posts/a-b-testing.html#step-2-pooled-proportion",
    "href": "posts/a-b-testing.html#step-2-pooled-proportion",
    "title": "A/B Testing: A Sample Analysis",
    "section": "Step 2: Pooled proportion",
    "text": "Step 2: Pooled proportion\nBecause under \\(H_0\\), both groups have the same conversion rate.\nTotal clicks = 3 + 6 = 9 Total users = 20\n\\(p_{\\text{pooled}} = \\frac{9}{20}=0.45\\)"
  },
  {
    "objectID": "posts/a-b-testing.html#step-3-standard-error",
    "href": "posts/a-b-testing.html#step-3-standard-error",
    "title": "A/B Testing: A Sample Analysis",
    "section": "Step 3: Standard error",
    "text": "Step 3: Standard error\n\\(SE = \\sqrt{p(1-p)\\left(\\frac{1}{n_A}+\\frac{1}{n_B}\\right)}\\)\n\\(SE = \\sqrt{0.45 \\times 0.55 \\times \\left(\\frac{1}{10}+\\frac{1}{10}\\right)}\\)\n\\(= \\sqrt{0.2475 \\times 0.2} = \\sqrt{0.0495} \\approx 0.2225\\)"
  },
  {
    "objectID": "posts/a-b-testing.html#step-4-z-statistic",
    "href": "posts/a-b-testing.html#step-4-z-statistic",
    "title": "A/B Testing: A Sample Analysis",
    "section": "Step 4: z-statistic",
    "text": "Step 4: z-statistic\n\\(z = \\frac{p_B - p_A}{SE} = \\frac{0.60 - 0.30}{0.2225} = \\frac{0.30}{0.2225} \\approx 1.35\\)"
  },
  {
    "objectID": "posts/a-b-testing.html#step-5-p-value",
    "href": "posts/a-b-testing.html#step-5-p-value",
    "title": "A/B Testing: A Sample Analysis",
    "section": "Step 5: p-value",
    "text": "Step 5: p-value\nFor a one-sided test, z = 1.35 ‚Üí p ‚âà 0.088."
  },
  {
    "objectID": "posts/a-b-testing.html#interpretation",
    "href": "posts/a-b-testing.html#interpretation",
    "title": "A/B Testing: A Sample Analysis",
    "section": "Interpretation",
    "text": "Interpretation\n\np-value = 0.088 &gt; 0.05\nWe fail to reject (H_0).\nEvidence is suggestive but not strong enough to conclude that the red button performs better.\n\n\nBusiness interpretation:\nEven though conversion increased from 30% ‚Üí 60%, the sample is very small (only 10 per group), so the difference is not statistically significant at Œ± = 0.05."
  },
  {
    "objectID": "posts/a-b-testing.html#what-we-can-say",
    "href": "posts/a-b-testing.html#what-we-can-say",
    "title": "A/B Testing: A Sample Analysis",
    "section": "What we can say",
    "text": "What we can say\n\nB looks promising: a +100% relative lift in conversions.\nBut the sample size is too small to be confident.\nA larger A/B test should be run."
  },
  {
    "objectID": "posts/clockplot.html",
    "href": "posts/clockplot.html",
    "title": "clockplot: Plot Event Times on a 24-Hour Clock",
    "section": "",
    "text": "My R package clockplot is now available on CRAN!\nThe primary goal of the clockplot is to plot event time on a clock chart. The length and color of the clock hands can be modified by certain qualitative and quantitative variables.\nAdditionally, the package can make a day chart, a week chart, or a month chart, or plan events in those periods.\nI would like everyone to visit the package website (generated automatically by pkgdown), explore the examples, and give wise advice\nTo see a quick example, see the attached plot. The plot shows times of earthquakes. Points are magnified as per magnitude. Length and color denote the depth of the epicenter. This allows us to find patterns in the event times as well as compare differences in time more easily and usefully than with other charts, such as a bar chart.\n\n\n\nclockplot\n\n\nThose having a github account, please visit the repo and please give a star :)"
  },
  {
    "objectID": "posts/sarimax-r.html",
    "href": "posts/sarimax-r.html",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "",
    "text": "Here‚Äôs a comprehensive guide to SARIMAX in R with examples and interpretation:"
  },
  {
    "objectID": "posts/sarimax-r.html#what-is-sarimax",
    "href": "posts/sarimax-r.html#what-is-sarimax",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "1. What is SARIMAX?",
    "text": "1. What is SARIMAX?\nSARIMAX = Seasonal AutoRegressive Integrated Moving Average with eXogenous variables\n\nSARIMA: Handles seasonality and trends\nX: Includes external predictors (covariates)"
  },
  {
    "objectID": "posts/sarimax-r.html#basic-syntax-in-r",
    "href": "posts/sarimax-r.html#basic-syntax-in-r",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "2. Basic Syntax in R",
    "text": "2. Basic Syntax in R\nlibrary(forecast)\n\n# Fit SARIMAX model\nmodel &lt;- Arima(y,\n               order = c(p, d, q),           # non-seasonal ARIMA order\n               seasonal = c(P, D, Q, S),     # seasonal order (S = period)\n               xreg = xreg_data)             # exogenous variables"
  },
  {
    "objectID": "posts/sarimax-r.html#example-1-simple-sarimax-with-one-external-variable",
    "href": "posts/sarimax-r.html#example-1-simple-sarimax-with-one-external-variable",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "3. Example 1: Simple SARIMAX with One External Variable",
    "text": "3. Example 1: Simple SARIMAX with One External Variable\nlibrary(forecast)\nlibrary(ggplot2)\n\n# Create sample data\nset.seed(123)\nn &lt;- 120\ntime &lt;- 1:n\n\n# Main time series with trend + seasonality\ny &lt;- 50 + 0.3*time + 10*sin(2*pi*time/12) + rnorm(n, 0, 5)\n\n# External variable (e.g., marketing spend)\nx1 &lt;- 20 + 0.1*time + rnorm(n, 0, 3)\n\n# Convert to time series object\ny_ts &lt;- ts(y, frequency = 12)\nx1_ts &lt;- ts(x1, frequency = 12)\n\n# Fit SARIMAX model\nsarimax_model &lt;- Arima(y_ts,\n                       order = c(1, 1, 0),      # Remove MA term\n                       seasonal = c(1, 1, 0),   # Remove seasonal MA\n                       xreg = x1_ts)\n\nsummary(sarimax_model)"
  },
  {
    "objectID": "posts/sarimax-r.html#example-2-multiple-external-variables",
    "href": "posts/sarimax-r.html#example-2-multiple-external-variables",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "4. Example 2: Multiple External Variables",
    "text": "4. Example 2: Multiple External Variables\n# Add second external variable\nx2 &lt;- 15 + 0.05*time + rnorm(n, 0, 2)\nxreg_matrix &lt;- cbind(x1_ts, x2_ts)\n\n# Fit model with multiple external variables\nsarimax_model2 &lt;- Arima(y_ts,\n                       order = c(1, 1, 1),\n                       seasonal = c(1, 1, 1),\n                       xreg = xreg_matrix)\n\nsummary(sarimax_model2)"
  },
  {
    "objectID": "posts/sarimax-r.html#model-diagnostics",
    "href": "posts/sarimax-r.html#model-diagnostics",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "5. Model Diagnostics",
    "text": "5. Model Diagnostics\n# Residual diagnostics\ncheckresiduals(sarimax_model)\n\n# Coefficients and significance\ncoef(sarimax_model)\nsqrt(diag(sarimax_model$var.coef))  # standard errors\n\n# Confidence intervals\nconfint(sarimax_model)"
  },
  {
    "objectID": "posts/sarimax-r.html#forecasting-with-external-variables",
    "href": "posts/sarimax-r.html#forecasting-with-external-variables",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "6. Forecasting with External Variables",
    "text": "6. Forecasting with External Variables\n# Create future values of external variables\nfuture_periods &lt;- 12\nx1_future &lt;- ts(30 + 0.1*(121:132), frequency = 12)\nx2_future &lt;- ts(20 + 0.05*(121:132), frequency = 12)\nxreg_future &lt;- cbind(x1_future, x2_future)\n\n# Generate forecasts\nforecast_result &lt;- forecast(sarimax_model2,\n                           h = future_periods,\n                           xreg = xreg_future)\n\n# Plot results\nautoplot(forecast_result) +\n  ggtitle(\"SARIMAX Forecast with External Variables\")"
  },
  {
    "objectID": "posts/sarimax-r.html#automated-model-selection",
    "href": "posts/sarimax-r.html#automated-model-selection",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "7. Automated Model Selection",
    "text": "7. Automated Model Selection\n# Let auto.arima select best SARIMAX model\nauto_model &lt;- auto.arima(y_ts,\n                        seasonal = TRUE,\n                        stepwise = TRUE,\n                        approximation = FALSE,\n                        xreg = xreg_matrix)\n\nsummary(auto_model)"
  },
  {
    "objectID": "posts/sarimax-r.html#real-dataset-example-airpassengers-with-exogenous-var",
    "href": "posts/sarimax-r.html#real-dataset-example-airpassengers-with-exogenous-var",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "8. Real Dataset Example (AirPassengers with exogenous var)",
    "text": "8. Real Dataset Example (AirPassengers with exogenous var)\n# Using AirPassengers dataset\ndata(\"AirPassengers\")\n\n# Create dummy external variable (e.g., economic index)\nset.seed(123)\neconomic_index &lt;- 100 + 0.5*time(AirPassengers) + rnorm(length(AirPassengers), 0, 10)\n\n# Fit SARIMAX\nair_model &lt;- Arima(AirPassengers,\n                  order = c(0, 1, 1),\n                  seasonal = c(0, 1, 1),\n                  xreg = economic_index)\n\n# Forecast with assumed future economic index\nfuture_econ &lt;- 150 + 0.5*(1961 + (0:11)/12)  # 1961 values\nair_forecast &lt;- forecast(air_model,\n                        h = 12,\n                        xreg = future_econ)\n\nautoplot(air_forecast)"
  },
  {
    "objectID": "posts/sarimax-r.html#interpretation-of-coefficients",
    "href": "posts/sarimax-r.html#interpretation-of-coefficients",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "9. Interpretation of Coefficients",
    "text": "9. Interpretation of Coefficients\nFor the model:\n# If output shows:\n# ar1 = 0.85, ma1 = -0.32, sar1 = 0.72, sma1 = -0.45, xreg1 = 0.65\nInterpretation: - ar1 = 0.85: Strong positive autocorrelation (persistence) - ma1 = -0.32: Negative momentum effects - sar1 = 0.72: Strong seasonal autocorrelation - sma1 = -0.45: Negative seasonal momentum - xreg1 = 0.65: 1-unit increase in external variable increases y by 0.65 units"
  },
  {
    "objectID": "posts/sarimax-r.html#important-notes",
    "href": "posts/sarimax-r.html#important-notes",
    "title": "SARIMAX Time Series Models with R Code",
    "section": "10. Important Notes",
    "text": "10. Important Notes\n\nStationarity: Ensure both y and xreg variables are stationary (use differencing if needed)\nCorrelation ‚â† Causation: External variables should theoretically make sense\nModel Validation: Always check residuals for autocorrelation\nOverfitting: Avoid too many external variables relative to data length\n\nThis gives you a solid foundation for implementing SARIMAX models in R!"
  },
  {
    "objectID": "posts/r-package-workflow.html",
    "href": "posts/r-package-workflow.html",
    "title": "R Package Development Workflow",
    "section": "",
    "text": "Here are the key devtools functions important in the R package development cycle.\n\nProject Setup\n\nusethis::create_package(): Creates a new package with the correct directory structure.\nusethis::use_git(): Initializes a Git repository for version control.\nusethis::use_r(): Creates a new .R file in the R/ directory.\n\n\n\n\nDevelopment and Documentation\n\ndevtools::load_all(): Loads all functions in the R/ directory, allowing you to quickly test them without installing the package.\ndevtools::document(): Generates documentation (.Rd files in the man/ directory) and the NAMESPACE file from roxygen2 comments.\ndevtools::install(): Installs the package from the source directory, making it available for use on your system.\n\n\n\n\nTesting and Checking\n\nusethis::use_testthat(): Sets up the testthat framework for unit testing.\nusethis::use_test(): Creates a new test file in tests/testthat/.\ndevtools::test(): Runs all the tests in the tests/testthat/ directory.\ndevtools::check(): Runs the comprehensive suite of R CMD check tests to identify errors, warnings, and notes.\ndevtools::check_win_devel(): Submits the package to the win-builder service to check for platform-specific issues on Windows.\n\n\n\n\nPublishing\n\nusethis::use_vignette(): Creates a new vignette (.Rmd file) for package tutorials.\npkgdown::build_site(): Builds a complete website for your package.\ndevtools::submit_cran(): Helps with the final steps of submitting your package to CRAN."
  },
  {
    "objectID": "posts/arima-sarima-r.html",
    "href": "posts/arima-sarima-r.html",
    "title": "ARIMA and SARIMA Time Series Models",
    "section": "",
    "text": "Here‚Äôs a clear, concise explanation of ARIMA, SARIMA, and related models ‚Äî followed by minimal R examples."
  },
  {
    "objectID": "posts/arima-sarima-r.html#minimal-arima-example-in-r",
    "href": "posts/arima-sarima-r.html#minimal-arima-example-in-r",
    "title": "ARIMA and SARIMA Time Series Models",
    "section": "Minimal ARIMA Example in R",
    "text": "Minimal ARIMA Example in R\nlibrary(forecast)\n\n# Use an example built-in dataset\nts_data &lt;- AirPassengers[1:60]   # Monthly passengers (first 5 years)\n\n# Fit a simple ARIMA model\nfit &lt;- auto.arima(ts_data)\n\n# Print model\nfit\n\n# Forecast next 12 periods\nforecast(fit, h = 12)\nauto.arima() automatically selects (p, d, q)."
  },
  {
    "objectID": "posts/arima-sarima-r.html#minimal-sarima-example-in-r",
    "href": "posts/arima-sarima-r.html#minimal-sarima-example-in-r",
    "title": "ARIMA and SARIMA Time Series Models",
    "section": "Minimal SARIMA Example in R",
    "text": "Minimal SARIMA Example in R\nlibrary(forecast)\n\nts_data &lt;- AirPassengers  # strong yearly seasonality\n\n# Fit SARIMA\nfit &lt;- auto.arima(ts_data, seasonal = TRUE)\n\nfit\nforecast(fit, h = 12)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a lecturer in statistics at Mymensingh Girls‚Äô Cadet College, Mymensingh. Earlier I taught statistics at Sylhet Cadet College & Pabna Cadet College. Before joining Cadet College service, I was employed as a research assistant at EAL, Dhaka. I also worked as a science contributor for The Daily Prothom Alo.\nI love to make my tecahing slides using coding (10 of them), also generating questions using Python, Bash, and Latex, among others, inside Rstudio, or using Quarto.\nI have, with the pen name Abdullah Adil Mahmud (‡¶Ü‡¶¨‡ßç‡¶¶‡ßÅ‡¶≤‡ßç‡¶Ø‡¶æ‡¶π ‡¶Ü‡¶¶‡¶ø‡¶≤ ‡¶Æ‡¶æ‡¶π‡¶Æ‡ßÅ‡¶¶), writt en SIX science books, which are all available on Rokomari.com.\nLearn more ‚Ä¶"
  },
  {
    "objectID": "posts/auto-arima-explanation.html",
    "href": "posts/auto-arima-explanation.html",
    "title": "Interpretation of an Auto SARIMAX model output in R",
    "section": "",
    "text": "The model we run is this\nNow the output we get is"
  },
  {
    "objectID": "posts/auto-arima-explanation.html#interpretation",
    "href": "posts/auto-arima-explanation.html#interpretation",
    "title": "Interpretation of an Auto SARIMAX model output in R",
    "section": "Interpretation",
    "text": "Interpretation\nHere‚Äôs a comprehensive interpretation of our SARIMAX model output:"
  },
  {
    "objectID": "posts/auto-arima-explanation.html#model-structure",
    "href": "posts/auto-arima-explanation.html#model-structure",
    "title": "Interpretation of an Auto SARIMAX model output in R",
    "section": "Model Structure",
    "text": "Model Structure\nSARIMAX(2,0,1)(2,1,1)[12] with external regressor\n\nNon-seasonal part: AR(2) + MA(1)\nSeasonal part: Seasonal AR(2) + Seasonal MA(1) with seasonal differencing (D=1)\nSeasonality: 12 months (monthly data)\nExternal regressor: One predictor variable (xreg)"
  },
  {
    "objectID": "posts/auto-arima-explanation.html#coefficients-interpretation",
    "href": "posts/auto-arima-explanation.html#coefficients-interpretation",
    "title": "Interpretation of an Auto SARIMAX model output in R",
    "section": "Coefficients Interpretation",
    "text": "Coefficients Interpretation\n\nNon-seasonal Components:\n\nAR(1) = -0.75: Strong negative autoregressive effect - high values tend to be followed by low values\nAR(2) = -0.09: Weak negative second-order autoregressive effect\nMA(1) = 0.79: Strong moving average effect - shocks persist for one period\n\n\n\nSeasonal Components (12-month cycle):\n\nSAR(1) = -0.19: Moderate negative seasonal autoregressive effect\nSAR(2) = 0.04: Very weak positive seasonal effect\nSMA(1) = -0.85: Strong negative seasonal moving average - seasonal shocks reverse quickly\n\n\n\nExternal Effects:\n\nDrift = 0.26: Positive trend component (0.26 units increase per period)\nxreg = 0.30: External variable has positive effect - 1 unit increase in xreg predicts 0.30 unit increase in y"
  },
  {
    "objectID": "posts/auto-arima-explanation.html#model-quality-assessment",
    "href": "posts/auto-arima-explanation.html#model-quality-assessment",
    "title": "Interpretation of an Auto SARIMAX model output in R",
    "section": "Model Quality Assessment",
    "text": "Model Quality Assessment\n\nStatistical Significance:\n\nSignificant coefficients: AR(1), MA(1), SMA(1), Drift (coefficient &gt; 2√ó standard error)\nBorderline: xreg (2.07√ó SE), SAR(1) (1.08√ó SE)\nInsignificant: AR(2), SAR(2) (coefficient &lt; SE)\n\n\n\nModel Fit Statistics:\n\nAIC = 666.56, BIC = 690.7: Good for model comparison (lower is better)\nLog-likelihood = -324.28: Baseline for model comparison\nœÉ¬≤ = 21.51: Error variance\n\n\n\nForecast Accuracy:\n\nRMSE = 4.23: Average forecast error magnitude\nMAE = 3.17: Average absolute error\nMAPE = 4.72%: Excellent accuracy (error &lt;5% of actual values)\nMASE = 0.52: Model performs 48% better than naive forecast"
  },
  {
    "objectID": "posts/auto-arima-explanation.html#key-insights-recommendations",
    "href": "posts/auto-arima-explanation.html#key-insights-recommendations",
    "title": "Interpretation of an Auto SARIMAX model output in R",
    "section": "Key Insights & Recommendations",
    "text": "Key Insights & Recommendations\n\nStrengths:\n\nExcellent predictive accuracy (MAPE &lt;5%)\nStrong seasonal patterns captured effectively\nGood model fit with reasonable complexity\nExternal variable adds value to predictions\n\n\n\nConcerns:\n\nOver-parameterization: AR(2) and SAR(2) appear unnecessary\nSome coefficients borderline significant\n\n\n\nSuggested Improvement:\n# Try simplified model\nbetter_model &lt;- Arima(y_ts, order = c(1,0,1), seasonal = c(1,1,1), xreg = xreg)\n\n\nBusiness Interpretation:\n\nThe time series shows strong seasonal patterns with 12-month cycles\nThere‚Äôs a positive underlying trend (0.26 units/period)\nThe external variable has moderate predictive power\nModel provides highly accurate forecasts with ~4.7% average error\n\nThis is generally a good quality model that should provide reliable forecasts for business planning."
  },
  {
    "objectID": "posts/regression-interaction.html",
    "href": "posts/regression-interaction.html",
    "title": "Interaction Effect in Regression Analysis",
    "section": "",
    "text": "An interaction effect means:\n\nThe effect of one variable on the outcome depends on the level of another variable.\n\nSo, the relationship between \\(X_1\\) and \\(Y\\) changes depending on the value of \\(X_2\\)."
  },
  {
    "objectID": "posts/regression-interaction.html#what-an-interaction-means-intuitive-view",
    "href": "posts/regression-interaction.html#what-an-interaction-means-intuitive-view",
    "title": "Interaction Effect in Regression Analysis",
    "section": "",
    "text": "An interaction effect means:\n\nThe effect of one variable on the outcome depends on the level of another variable.\n\nSo, the relationship between \\(X_1\\) and \\(Y\\) changes depending on the value of \\(X_2\\)."
  },
  {
    "objectID": "posts/regression-interaction.html#a-simple-regression-without-interaction",
    "href": "posts/regression-interaction.html#a-simple-regression-without-interaction",
    "title": "Interaction Effect in Regression Analysis",
    "section": "2. A simple regression without interaction",
    "text": "2. A simple regression without interaction\nSay we model income as a function of gender and education:\n\\(\\text{Income} = \\beta_0 + \\beta_1(\\text{Gender}) + \\beta_2(\\text{Education}) + \\epsilon\\)\nHere:\n\n\\(\\beta_1\\): average difference between males and females (assuming Gender is dummy coded, say Male=1, Female=0)\n\\(\\beta_2\\): effect of moving from one education level to another\nThe two effects are independent ‚Äî the gender gap is the same across all education levels."
  },
  {
    "objectID": "posts/regression-interaction.html#add-an-interaction-term",
    "href": "posts/regression-interaction.html#add-an-interaction-term",
    "title": "Interaction Effect in Regression Analysis",
    "section": "3. Add an interaction term",
    "text": "3. Add an interaction term\nNow we include a product term:\n\\(\\text{Income} = \\beta_0 + \\beta_1(\\text{Gender}) + \\beta_2(\\text{Education}) + \\beta_3(\\text{Gender} \\times \\text{Education}) + \\epsilon\\)\nThat last term ‚Äî \\(\\beta_3(\\text{Gender} \\times \\text{Education})\\) ‚Äî is the interaction.\n\nMeaning:\nIt tells us whether the effect of education differs by gender.\n\nIf \\(\\beta_3 = 0\\): no interaction ‚Äî both genders gain equally from higher education.\nIf \\(\\beta_3 &gt; 0\\): the return to education (effect on income) is greater for males than females.\nIf \\(\\beta_3 &lt; 0\\): the return to education is greater for females than males."
  },
  {
    "objectID": "posts/regression-interaction.html#example-with-numbers",
    "href": "posts/regression-interaction.html#example-with-numbers",
    "title": "Interaction Effect in Regression Analysis",
    "section": "4. Example with numbers",
    "text": "4. Example with numbers\nSuppose you fit this model (Gender=1 for Male, 0 for Female; Education=years of schooling):\n\\(\\text{Income} = 20{,}000 + 5{,}000(\\text{Education}) + 3{,}000(\\text{Gender}) + 1{,}000(\\text{Gender} \\times \\text{Education})\\)\nInterpretation:\n\n\n\n\n\n\n\nTerm\nMeaning\n\n\n\n\n20,000\nAverage income for a female with 0 years of education (baseline).\n\n\n5,000\nEach year of education increases income by $5,000 for females.\n\n\n3,000\nMales earn $3,000 more than females at 0 years of education.\n\n\n1,000\nFor males, the effect of each additional year of education is $1,000 higher.\n\n\n\nSo:\n\nFor females: effect of education = 5,000 per year\nFor males: effect of education = 5,000 + 1,000 = 6,000 per year\n\nThat difference (1,000) is the interaction effect."
  },
  {
    "objectID": "posts/regression-interaction.html#in-general",
    "href": "posts/regression-interaction.html#in-general",
    "title": "Interaction Effect in Regression Analysis",
    "section": "5. In general",
    "text": "5. In general\nInteractions can occur between:\n\nTwo categorical variables (e.g., gender √ó marital status)\nCategorical √ó continuous (e.g., gender √ó education years)\nTwo continuous (e.g., age √ó income in predicting health)\n\nEach type changes the interpretation slightly ‚Äî but the core idea is always:\n\nthe slope (or effect) of one predictor depends on the value of another."
  },
  {
    "objectID": "posts/ar-ma-time-series.html",
    "href": "posts/ar-ma-time-series.html",
    "title": "AutoRegressive and Moving Average Time Series Models with R Code",
    "section": "",
    "text": "Here‚Äôs a comprehensive explanation of AR (AutoRegressive) and MA (Moving Average) models and their parameters:"
  },
  {
    "objectID": "posts/ar-ma-time-series.html#ar-model-autoregressive",
    "href": "posts/ar-ma-time-series.html#ar-model-autoregressive",
    "title": "AutoRegressive and Moving Average Time Series Models with R Code",
    "section": "1. AR Model (AutoRegressive)",
    "text": "1. AR Model (AutoRegressive)\n\nConcept:\nAn AR model predicts future values based on past values of the same variable.\n\n\nAR(p) Model Formula:\n\\(Y_t = c + \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2} + \\cdots + \\phi_p Y_{t-p} + \\epsilon_t\\) Where:\n\n\\(Y_t\\) = value at time (t)\n\\(c\\) = constant (mean term)\n\\(\\phi_1, \\phi_2, \\dots, \\phi_p\\) = AR parameters (autoregressive coefficients)\n\\(p\\) = order of the model (number of lagged terms)\n\\(\\epsilon_t\\) = white noise error term\n\n\n\n\nAR Parameters Interpretation:\n\n\\(\\phi_1\\): Effect of the most recent observation \\((Y_{t-1})\\) on current value\n\\(\\phi_2\\): Effect of two periods back \\((Y_{t-2})\\)\n\\(\\phi_p\\): Effect of p periods back \\((Y_{t-p})\\)\n\n\n\nExample: AR(2) Model\n\\(Y_t = 0.5 + 0.7Y_{t-1} + 0.2Y_{t-2} + \\epsilon_t\\)\nInterpretation: - Current value depends 70% on last period‚Äôs value - Plus 20% on the value from two periods ago - Plus a constant 0.5 and random noise\n\n\n\nStationarity Condition for AR:\nFor AR(1): \\(|\\phi_1| &lt; 1\\)\nFor AR(p): All roots of characteristic equation must lie outside unit circle"
  },
  {
    "objectID": "posts/ar-ma-time-series.html#ma-model-moving-average",
    "href": "posts/ar-ma-time-series.html#ma-model-moving-average",
    "title": "AutoRegressive and Moving Average Time Series Models with R Code",
    "section": "2. MA Model (Moving Average)",
    "text": "2. MA Model (Moving Average)\n\nConcept:\nAn MA model predicts future values based on past forecast errors.\n\n\nMA(q) Model Formula:\n\\(Y_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\cdots + \\theta_q \\epsilon_{t-q}\\)\nWhere:\n\n\\(\\mu\\) = mean of the series\n\\(\\theta_1, \\theta_2, \\dots, \\theta_q\\) = MA parameters\n\\(q\\) = order of the model\n\\(\\epsilon_t, \\epsilon_{t-1}, \\dots\\) = error terms (white noise)\n\n\n\n\nMA Parameters Interpretation:\n\n\\(\\theta_1\\): Effect of last period‚Äôs shock on current value\n\\(\\theta_2\\): Effect of two periods ago shock\n\\(\\theta_q\\): Effect of q periods ago shock\n\n\n\nExample: MA(2) Model\n\\(Y_t = 10 + \\epsilon_t - 0.4\\epsilon_{t-1} + 0.3\\epsilon_{t-2}\\)\nInterpretation: - Series has mean 10 - Current value affected by: - Current random shock \\((\\epsilon_t)\\)) - -40% of last period‚Äôs shock - +30% of shock from two periods ago\n\n\n\nInvertibility Condition for MA:\nFor MA(1): \\(|\\theta_1| &lt; 1\\) For MA(q): All roots of characteristic equation must lie outside unit circle"
  },
  {
    "objectID": "posts/ar-ma-time-series.html#key-differences",
    "href": "posts/ar-ma-time-series.html#key-differences",
    "title": "AutoRegressive and Moving Average Time Series Models with R Code",
    "section": "3. Key Differences",
    "text": "3. Key Differences\n\n\n\nFeature\nAR Model\nMA Model\n\n\n\n\nDepends on\nPast values of series\nPast forecast errors\n\n\nMemory\nInfinite (theoretically)\nFinite (q periods)\n\n\nACF\nDecays gradually\nCuts off after lag q\n\n\nPACF\nCuts off after lag p\nDecays gradually\n\n\nUse Case\nPersistent trends\nShock-driven series"
  },
  {
    "objectID": "posts/ar-ma-time-series.html#parameter-estimation-in-practice",
    "href": "posts/ar-ma-time-series.html#parameter-estimation-in-practice",
    "title": "AutoRegressive and Moving Average Time Series Models with R Code",
    "section": "4. Parameter Estimation in Practice",
    "text": "4. Parameter Estimation in Practice\n\nIn R:\nlibrary(forecast)\n\n# Fit AR model\nar_model &lt;- Arima(ts_data, order = c(2, 0, 0))  # AR(2)\n\n# Fit MA model\nma_model &lt;- Arima(ts_data, order = c(0, 0, 2))  # MA(2)\n\n# View parameters\nsummary(ar_model)\nsummary(ma_model)\n\n\nTypical Parameter Ranges:\n\nAR parameters: Usually between -1 and 1\nMA parameters: Usually between -1 and 1\nSignificant parameters indicate important lags"
  },
  {
    "objectID": "posts/ar-ma-time-series.html#real-world-examples",
    "href": "posts/ar-ma-time-series.html#real-world-examples",
    "title": "AutoRegressive and Moving Average Time Series Models with R Code",
    "section": "5. Real-World Examples",
    "text": "5. Real-World Examples\n\nAR Example - Stock Prices:\n# Stock prices often show AR behavior\n# AR(1): Today's price = 0.95 √ó Yesterday's price + noise\n\n\nMA Example - Inventory Systems:\n# Inventory shocks affect future periods\n# MA(1): Today's demand = mean - 0.6 √ó Yesterday's forecast error + noise"
  },
  {
    "objectID": "posts/ar-ma-time-series.html#model-identification",
    "href": "posts/ar-ma-time-series.html#model-identification",
    "title": "AutoRegressive and Moving Average Time Series Models with R Code",
    "section": "6. Model Identification",
    "text": "6. Model Identification\n\nUsing ACF/PACF plots:\n\nAR signature: PACF cuts off at lag p, ACF decays\nMA signature: ACF cuts off at lag q, PACF decays\n\n\n\nInformation Criteria:\n\nUse AIC/BIC to choose optimal p and q\nLower values indicate better model fit"
  },
  {
    "objectID": "posts/ar-ma-time-series.html#combined-model---armapq",
    "href": "posts/ar-ma-time-series.html#combined-model---armapq",
    "title": "AutoRegressive and Moving Average Time Series Models with R Code",
    "section": "7. Combined Model - ARMA(p,q)",
    "text": "7. Combined Model - ARMA(p,q)\n\\(Y_t = c + \\phi_1 Y_{t-1} + \\cdots + \\phi_p Y_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\cdots + \\theta_q \\epsilon_{t-q}\\)\nCombines both past values AND past errors for forecasting.\n\nKey Takeaway: AR models capture inertia/persistence, while MA models capture shock effects. The parameters \\((\\phi\\)) and \\(\\theta\\)) quantify these relationships and are estimated from data to best fit the time series pattern."
  },
  {
    "objectID": "posts/t-test-to-anova.html",
    "href": "posts/t-test-to-anova.html",
    "title": "From t-test to Anova",
    "section": "",
    "text": "Let‚Äôs build a t-test and then showing how it generalizes naturally into ANOVA (Analysis of Variance)."
  },
  {
    "objectID": "posts/t-test-to-anova.html#step-1.-the-t-test-comparing-two-means",
    "href": "posts/t-test-to-anova.html#step-1.-the-t-test-comparing-two-means",
    "title": "From t-test to Anova",
    "section": "Step 1. The t-test ‚Äî comparing two means",
    "text": "Step 1. The t-test ‚Äî comparing two means\nLet‚Äôs imagine two groups of students and their test scores:\n\n\n\nGroup\nScores\n\n\n\n\nGroup A\n70, 75, 80\n\n\nGroup B\n85, 90, 95\n\n\n\nWe want to know:\n\nAre the mean scores of Group A and Group B significantly different?\n\n\nHypotheses\n\\(H_0: \\mu_A = \\mu_B \\quad \\text{(means are equal)}\\)\n\\(H_1: \\mu_A \\ne \\mu_B\\)\n\n\nLogic of the t-test\nWe calculate:\n\nThe difference between sample means \\(\\bar X_A - \\bar X_B\\)\nThe standard error of that difference (based on the variances and sample sizes)\nThe t-statistic\n\\(t = \\frac{(\\bar X_A - \\bar X_B)}{SE}\\)\n\nIf the difference is large relative to its expected variation, we reject \\(H_0\\).\n\n\n\nIntuition\n\nThe numerator measures how far apart the groups are.\nThe denominator measures how noisy the data are.\nA large t-value ‚áí groups differ more than we‚Äôd expect by chance.\n\nSo the two-sample t-test compares between-group difference to within-group variability."
  },
  {
    "objectID": "posts/t-test-to-anova.html#step-2.-extending-to-more-than-two-groups",
    "href": "posts/t-test-to-anova.html#step-2.-extending-to-more-than-two-groups",
    "title": "From t-test to Anova",
    "section": "Step 2. Extending to more than two groups",
    "text": "Step 2. Extending to more than two groups\nNow add a third group:\n\n\n\nGroup\nScores\n\n\n\n\nGroup A\n70, 75, 80\n\n\nGroup B\n85, 90, 95\n\n\nGroup C\n60, 65, 70\n\n\n\nNow what if we ask:\n\nAre all group means equal?\n\nYou could do multiple t-tests (A vs B, A vs C, B vs C), but that inflates the chance of false positives. Instead, ANOVA does it all at once."
  },
  {
    "objectID": "posts/t-test-to-anova.html#step-3.-anova-conceptually",
    "href": "posts/t-test-to-anova.html#step-3.-anova-conceptually",
    "title": "From t-test to Anova",
    "section": "Step 3. ANOVA conceptually",
    "text": "Step 3. ANOVA conceptually\n\nHypotheses\n\\(H_0: \\mu_A = \\mu_B = \\mu_C \\quad \\text{(all equal)}\\)\n\\(H_1: \\text{At least one mean differs}\\)\n\n\nHow ANOVA works\nANOVA decomposes total variability into two parts:\n\\(\\text{Total Variation} = \\text{Between-group Variation} + \\text{Within-group Variation}\\)\nIt then forms a ratio:\n\\(F = \\frac{\\text{Between-group Mean Square}}{\\text{Within-group Mean Square}}\\)\n\nIf \\(H_0\\) is true, both parts estimate the same thing ‚Üí \\(F \\approx 1\\).\nIf group means differ more than expected, \\(F &gt; 1\\) ‚Üí reject \\(H_0\\)."
  },
  {
    "objectID": "posts/t-test-to-anova.html#step-4.-conceptual-link-between-t-and-f",
    "href": "posts/t-test-to-anova.html#step-4.-conceptual-link-between-t-and-f",
    "title": "From t-test to Anova",
    "section": "Step 4. Conceptual link between t and F",
    "text": "Step 4. Conceptual link between t and F\nFor two groups, ANOVA and t-test give the same result:\n\\(F = t^2\\)\nSo ANOVA is just a generalization of the t-test from 2 groups to many groups.\n\n\n\n\n\n\n\n\n\nTest\nGroups\nStatistic\nDistribution\n\n\n\n\nt-test\n2\n\\(t\\)\nt-distribution\n\n\nANOVA\n‚â• 2\n\\(F = \\frac{\\text{Between}}{\\text{Within}}\\)\nF-distribution"
  },
  {
    "objectID": "posts/t-test-to-anova.html#step-5.-interpretation",
    "href": "posts/t-test-to-anova.html#step-5.-interpretation",
    "title": "From t-test to Anova",
    "section": "Step 5. Interpretation",
    "text": "Step 5. Interpretation\n\nIf \\(F\\) (or \\(|t|\\)) is large and the p-value &lt; 0.05, we reject \\(H_0\\). ‚Üí The means are not all equal.\nIf not, we conclude that differences among sample means could just be random noise."
  },
  {
    "objectID": "posts/t-test-to-anova.html#summary-table",
    "href": "posts/t-test-to-anova.html#summary-table",
    "title": "From t-test to Anova",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\nAspect\nt-test\nANOVA\n\n\n\n\nPurpose\nCompare two means\nCompare two or more means\n\n\nHypothesis\n\\(H_0: \\mu_1 = \\mu_2\\)\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\dots\\)\n\n\nStatistic\nt\nF\n\n\nLogic\nDifference of means / error\nRatio of between-group / within-group variance\n\n\nLink\n\\(F = t^2\\) for 2 groups\n‚Äî"
  },
  {
    "objectID": "posts/t-test-to-anova.html#why-not-many-t-tests",
    "href": "posts/t-test-to-anova.html#why-not-many-t-tests",
    "title": "From t-test to Anova",
    "section": "Why not many t-tests?",
    "text": "Why not many t-tests?\nDoing multiple t-tests increases the Type I error rate (false positive probability).\nLet us see how.\n\nSuppose you have \\(k = 3\\) groups:\n\n\\(G_1, G_2, G_3\\)\n\nTo compare them, you could do pairwise t-tests:\n\\(G_1 \\text{ vs } G_2,\\quad G_1 \\text{ vs } G_3,\\quad G_2 \\text{ vs } G_3\\)\nThat‚Äôs \\(C(k,2) = 3\\) tests.\nEach test has significance level \\(\\alpha = 0.05\\). So the chance of no false positive across all tests = \\((1-\\alpha)^m\\), where \\(m\\) = number of tests.\nHence, the overall false positive rate (familywise error rate) is:\n\\(\\text{FWER} = 1 - (1 - \\alpha)^m\\)\nFor \\(k=3\\) groups, \\(m=3\\):\n\\(\\text{FWER} = 1 - (1 - 0.05)^3 = 1 - 0.95^3 = 0.1426\\)\nSo even if all population means are equal, there‚Äôs ‚âà14% chance you‚Äôll (wrongly) find at least one ‚Äúsignificant difference‚Äù.\nThis is why ANOVA tests all means simultaneously with a single Œ± = 0.05 ‚Äî controlling the false positive rate."
  },
  {
    "objectID": "posts/t-test-to-anova.html#minimal-empirical-example",
    "href": "posts/t-test-to-anova.html#minimal-empirical-example",
    "title": "From t-test to Anova",
    "section": "Minimal empirical example",
    "text": "Minimal empirical example\nLet‚Äôs make up a small dataset:\n\n\n\nGroup\nValues\n\n\n\n\nA\n5, 6, 7\n\n\nB\n6, 7, 8\n\n\nC\n5, 7, 9\n\n\n\nAll groups have similar means (~6.5‚Äì7). True means are equal (in population), but random variation exists.\nNow:\n\nStep 1. Pairwise t-tests\nWe do:\n\nA vs B ‚Üí p = 0.08\nA vs C ‚Üí p = 0.04\nB vs C ‚Üí p = 0.06\n\nOne of them (A vs C) is &lt;0.05 ‚Üí you‚Äôd claim a ‚Äúsignificant‚Äù difference. But that‚Äôs a false positive, since groups were drawn from the same population.\nIf you repeated this experiment 1000 times, around 14% of runs would falsely detect something significant ‚Äî matching our theoretical 0.1426."
  },
  {
    "objectID": "posts/t-test-to-anova.html#key-takeaway",
    "href": "posts/t-test-to-anova.html#key-takeaway",
    "title": "From t-test to Anova",
    "section": "Key takeaway",
    "text": "Key takeaway\n\n\n\n\n\n\n\n\n\nMethod\nNumber of tests\nNominal Œ± per test\nFamilywise Œ± (true false positive rate)\n\n\n\n\nOne-way ANOVA\n1\n0.05\n0.05\n\n\nThree t-tests\n3\n0.05\n0.14\n\n\nTen t-tests\n10\n0.05\n0.40"
  },
  {
    "objectID": "posts/spatio-temporal.html",
    "href": "posts/spatio-temporal.html",
    "title": "Spatio-temporal Analysis Workflow",
    "section": "",
    "text": "Spatio-temporal analysis sits right at the intersection of statistics, data science, GIS, and environmental applications.\nüìö Step 1: Build Foundations\nSpatial Statistics"
  },
  {
    "objectID": "posts/spatio-temporal.html#time-series-temporal-analysis",
    "href": "posts/spatio-temporal.html#time-series-temporal-analysis",
    "title": "Spatio-temporal Analysis Workflow",
    "section": "Time Series / Temporal Analysis",
    "text": "Time Series / Temporal Analysis\n\nRefresh time series models (ARIMA, state-space, spectral methods).\nAdd temporal clustering and forecasting methods."
  },
  {
    "objectID": "posts/spatio-temporal.html#spatio-temporal-models",
    "href": "posts/spatio-temporal.html#spatio-temporal-models",
    "title": "Spatio-temporal Analysis Workflow",
    "section": "Spatio-Temporal Models",
    "text": "Spatio-Temporal Models\n\nCombine both: spatio-temporal kriging, Gaussian random fields, Bayesian hierarchical models.\nBook: Hierarchical Modelling of Spatial Data Using R-INLA (Blangiardo & Cameletti).\n\nüõ† Step 2: Learn the Tools"
  },
  {
    "objectID": "posts/spatio-temporal.html#r-packages",
    "href": "posts/spatio-temporal.html#r-packages",
    "title": "Spatio-temporal Analysis Workflow",
    "section": "R packages",
    "text": "R packages\n\nsf (modern spatial objects)\nstars (spatio-temporal arrays)\nterra (raster/vector operations)\nspacetime (older but still used)\ngstat (variograms, kriging)\nspdep (spatial dependence)\nINLA (Bayesian spatio-temporal modeling)\nPython equivalents (optional, if you want dual skillset): geopandas, xarray, rasterio, pySTL, pysal, scikit-mobility\n\nüî¨ Step 3: Practice with Data"
  },
  {
    "objectID": "posts/spatio-temporal.html#sources-of-free-spatio-temporal-datasets",
    "href": "posts/spatio-temporal.html#sources-of-free-spatio-temporal-datasets",
    "title": "Spatio-temporal Analysis Workflow",
    "section": "Sources of free spatio-temporal datasets:",
    "text": "Sources of free spatio-temporal datasets:\n\nEarth observation: NASA EarthData, Copernicus (Sentinel satellites)\nClimate: ERA5 reanalysis (ECMWF)\nHealth: COVID-19 spatio-temporal data (Johns Hopkins)\nUrban/mobility: OpenStreetMap, Google Mobility Reports\nYou could start with simple projects:\nMapping air quality trends across time.\nSpatio-temporal spread of disease (e.g., dengue in Bangladesh).\nDetecting land cover change from satellite images.\n\nü§ù Step 4: Contribute"
  },
  {
    "objectID": "posts/spatio-temporal.html#open-source-contributions",
    "href": "posts/spatio-temporal.html#open-source-contributions",
    "title": "Spatio-temporal Analysis Workflow",
    "section": "Open-Source Contributions",
    "text": "Open-Source Contributions\n\nHelp improve documentation or examples in sf, stars, or spacetime.\nBuild teaching vignettes for gstat or spdep."
  },
  {
    "objectID": "posts/spatio-temporal.html#research-contributions",
    "href": "posts/spatio-temporal.html#research-contributions",
    "title": "Spatio-temporal Analysis Workflow",
    "section": "Research Contributions",
    "text": "Research Contributions\n\nApply spatio-temporal models to a new real-world problem (climate, urban growth, seismicity).\nPublish datasets + reproducible code (on GitHub + Zenodo)."
  },
  {
    "objectID": "posts/spatio-temporal.html#community-involvement",
    "href": "posts/spatio-temporal.html#community-involvement",
    "title": "Spatio-temporal Analysis Workflow",
    "section": "Community Involvement",
    "text": "Community Involvement\n\nJoin R-Spatial community (https://r-spatial.org).\nFollow Edzer Pebesma, Roger Bivand, and Virgilio G√≥mez-Rubio.\nPresent small case studies in workshops/webinars.\n\n‚ö° A good starting project for you could be:\n‚ÄúSpatio-temporal visualization of earthquake aftershocks in Bangladesh/Asia using USGS data‚Äù"
  },
  {
    "objectID": "posts/z-score.html",
    "href": "posts/z-score.html",
    "title": "Z-score: What it is and what it does",
    "section": "",
    "text": "A z-score (also known as a standard score or z-value) measures how many standard deviations a data point is from the mean of a distribution. It‚Äôs a way of standardizing individual data points so they can be compared, regardless of the scale of the data.\n\nHow to calculate the z-score:\nThe formula for the z-score of a data point is:\n\\(z = \\frac{X - \\mu}{\\sigma}\\)\nWhere:\n\n\\(X\\) = the value of the data point.\n\\(\\mu\\) = the mean (average) of the dataset.\n\\(\\sigma\\) = the standard deviation of the dataset.\n\n\n\nSteps to calculate the z-score:\n\nFind the mean of the dataset.\nFind the standard deviation of the dataset.\nSubtract the mean from the data point you‚Äôre interested in.\nDivide the result by the standard deviation.\n\n\n\nExample:\nImagine you have the following dataset of test scores: [80, 85, 90, 95, 100]\n\nMean (Œº): ((80 + 85 + 90 + 95 + 100) / 5 = 90)\nStandard Deviation (œÉ): Calculate the standard deviation of the dataset (you could use a standard formula or a calculator for this). Let‚Äôs say it‚Äôs 7.91.\nTo find the z-score for a score of 85:\n\\(z = \\frac{85 - 90}{7.91} \\approx -0.63\\)\nThis means the score of 85 is 0.63 standard deviations below the mean.\n\n\n\n\nCommon uses of the z-score:\n\nStandardizing data: Z-scores are used to standardize data, especially when you want to compare values from different datasets with different units or scales.\nIdentifying outliers: A data point with a z-score greater than +3 or less than -3 is often considered an outlier because it lies more than 3 standard deviations away from the mean.\nProbability and normal distribution: In statistics, z-scores are crucial when working with the normal distribution. They can be used to find the probability of a value occurring within a normal distribution by looking up the z-score in a standard normal distribution table (or using statistical software).\nComparing scores across different distributions: For example, in education, z-scores allow you to compare scores from different tests, even if those tests have different scales (e.g., SAT vs.¬†ACT scores). You can convert raw scores into z-scores to compare relative performance.\nRisk assessment and finance: In finance, z-scores can be used to assess the risk or financial stability of a company. The Altman Z-score, for instance, is used to predict the likelihood of bankruptcy.\nQuality control and manufacturing: In quality control, z-scores help assess whether a product meets specifications, identifying whether the production process is consistent or if corrective action is needed."
  },
  {
    "objectID": "posts/iqr.html",
    "href": "posts/iqr.html",
    "title": "IQR in Statistics",
    "section": "",
    "text": "The Interquartile Range (IQR) is a measure of statistical dispersion that describes the spread of the middle 50% of data. It is calculated as:\n\\(\\text{IQR} = Q_3 - Q_1\\)\nwhere \\(Q_1\\) is the 25th percentile and \\(Q_3\\) is the 75th percentile.\n\n\nUsefulness of IQR\n\nRobust to outliers ‚Äì Unlike the range or standard deviation, the IQR is not influenced by extreme values.\nIdentifies variability of the central portion of the data.\nUsed to detect outliers ‚Äì Often, values below \\(Q_1 - 1.5 \\times \\text{IQR}\\) or above \\(Q_3 + 1.5 \\times \\text{IQR}\\) are considered outliers.\nHelps in comparing distributions ‚Äì Especially when using box plots.\n\n\n\n\nExample: Exam Scores\nSuppose the exam scores (out of 100) of 15 students are:\n\\(55, 60, 65, 70, 72, 75, 78, 80, 82, 85, 88, 90, 95, 98, 99\\)\nStep 1: Find \\(Q_1\\) and \\(Q_3\\) - \\(Q_1\\) = median of the first half (excluding overall median if odd) = 70 - \\(Q_3\\) = median of the second half = 90\nStep 2: Calculate IQR\n\\(\\text{IQR} = 90 - 70 = 20\\)\nStep 3: Interpret - The middle 50% of students scored between 70 and 90. - The spread of these central scores is 20 points.\nStep 4: Detect outliers Lower fence: \\(70 - 1.5 \\times 20 = 40\\) Upper fence: \\(90 + 1.5 \\times 20 = 120\\) No scores below 40 or above 120 ‚Üí No outliers.\n\n\n\nWhy IQR is useful here\n\nIf one student scored 20 instead of 55, the range would change drastically, but the IQR would remain the same.\nIQR gives a clearer picture of the typical spread unaffected by extremes."
  },
  {
    "objectID": "posts/micro-XRF.html",
    "href": "posts/micro-XRF.html",
    "title": "Micro-XRF: super-powered, non-destructive chemical camera",
    "section": "",
    "text": "The Super-Sleuth ‚ÄúChemical Camera‚Äù\nImagine you have a tiny painting, and you want to know exactly what it‚Äôs made of‚Äînot just the colors, but the actual elements (like iron, copper, lead, calcium) in every single brushstroke.\nMicro-XRF is like a super-powered, non-destructive chemical camera. It doesn‚Äôt just take a picture of what something looks like; it takes a detailed map of what it‚Äôs made of, point by tiny point.\n\n\n\nSimple Breakdown:\n1. The ‚ÄúMicro‚Äù Part:\n\nThis is the magnifying glass. The machine uses special optics to focus its X-ray beam down to an incredibly small spot‚Äîoften as tiny as the width of a human hair or smaller. This lets it scan specific, microscopic areas (like a single mineral grain, a paint chip, or a circuit board trace).\n\n2. The ‚ÄúXRF‚Äù Part (X-Ray Fluorescence):\nThis is the elemental detective part. It works in three steps:\n\nStep 1: Zap! The machine fires a focused beam of high-energy X-rays at a tiny spot on your sample.\nStep 2: Excite! When the X-rays hit an atom in the sample, they knock an electron out of its inner shell. This makes the atom unstable.\nStep 3: Shine! To become stable again, an electron from an outer shell drops in to fill the hole. When it does this, it releases a tiny burst of energy in the form of a secondary X-ray. This is the ‚Äúfluorescence.‚Äù\nThe Key: Every chemical element (iron, gold, silicon, etc.) releases a unique, signature X-ray with a specific energy. It‚Äôs like each element has its own distinct ‚Äúfingerprint‚Äù color in the X-ray spectrum.\n\n3. Putting It All Together:\nThe machine has a detector that ‚Äúlistens‚Äù for these fluorescent X-rays and reads their ‚Äúfingerprints.‚Äù It then moves the beam point-by-point across the sample, building up a map.\nThe result is a set of colorful images where each color shows the distribution and concentration of a specific element across your sample.\n\n\n\nThe Classic Analogy: The Pinball Machine\n\nThe X-ray Beam is like the plunger that launches the pinball (the high-energy X-ray photon).\nThe Sample‚Äôs Atoms are the bumpers and targets.\nThe ‚ÄúFluorescence‚Äù is like the specific sound and lights that go off when you hit a particular target. A bell means you hit the Iron target. A siren means you hit the Copper target.\nBy listening to the sounds (detecting the X-rays), you know exactly what targets (elements) you hit and where.\n\n\n\n\nWhat Does the Output Look Like?\nYou get beautiful elemental maps. For example, if you scan an old coin: * One map might show copper (in red) everywhere. * Another map might show tin (in blue) only in certain areas, revealing it‚Äôs actually bronze. * Another might show silver (in green) only in the raised design, proving it was silver-plated.\n\n\nKey Features in Simple Terms:\n\nNon-Destructive: It doesn‚Äôt hurt the sample. You can scan a priceless painting or a rare meteorite without cutting or damaging it.\nElemental, Not Molecular: It tells you what elements are there (iron, calcium, lead), but not necessarily what compounds they are in (hematite, calcium carbonate, lead white paint). For that, you‚Äôd need a partner technique like Raman spectroscopy.\nFrom Major to Trace: It can detect elements from large concentrations down to very tiny traces (parts per million).\n\n\n\nWhere Is It Used?\n\nArt & Archaeology: Is that Picasso genuine? What pigments did ancient Egyptians use?\nGeology: What minerals are in this rock, and how are they zoned?\nMaterials Science: Are there impurities in this solar cell? Is the coating on this metal even?\nBiology/Medicine: Where does iron or calcium accumulate in a piece of bone or a plant leaf?\n\nIn a nutshell: Micro-XRF is a high-tech magnifying glass that zaps tiny spots with X-rays and listens to their unique ‚Äúelemental song‚Äù to create a map of what things are made of, at a microscopic level."
  },
  {
    "objectID": "posts/mass-spectrometry-imaging.html",
    "href": "posts/mass-spectrometry-imaging.html",
    "title": "Understanding Mass Spectrometry Imaging",
    "section": "",
    "text": "The ‚ÄúMolecular Camera‚Äù for Any Surface\nImagine you could take a photograph of a slice of tissue, a leaf, or a painting, but instead of seeing colors, you see a map of hundreds of different molecules‚Äîfats, sugars, drugs, proteins‚Äîexactly where they are located.\nThat‚Äôs MSI. It‚Äôs a technique that combines the molecular identification power of a mass spectrometer with the spatial mapping of a microscope.\n\n\n\nThe Simple Analogy: The ‚ÄúMolecular Spray-Painter & Detective‚Äù\nThink of it like this:\n\nYou have a slice of something to analyze (e.g., a thin slice of a mouse brain, a plant leaf, or a cross-section of a pill).\nA very focused, tiny ‚Äúprobe‚Äù (often a laser or an ion beam) moves pixel-by-pixel across the sample, like the nozzle of an ultra-precise spray painter.\nAt each pixel, the probe ‚Äúsprays off‚Äù (ionizes) a tiny bit of material from that exact spot, turning molecules into charged particles (ions).\nThese ions are then sucked into the mass spectrometer‚Äîthe ‚Äúdetective‚Äù‚Äîwhich weighs each one with extreme precision to determine its mass-to-charge ratio (its molecular fingerprint).\nThe computer records which molecules were present at that exact (x, y) coordinate.\nAfter scanning every pixel, the software reconstructs all the data into images, where the brightness of a pixel shows how much of a specific molecule was present at that location.\n\n\n\n\nHow It Works (The 3-Step Process)\n\n\n\n\n\n\n\n\n\nStep\nName\nWhat Happens (Simply)\nReal-World Analogy\n\n\n\n\n1\nIonization\nA focused beam (laser/ion beam) hits a tiny spot, blasting molecules off the surface and giving them an electrical charge.\nA targeted water jet knocks a specific colored sand off a detailed mosaic, one tile at a time.\n\n\n2\nMass Analysis\nThe charged molecules (ions) fly through a mass spectrometer, which sorts and weighs them based on their mass and charge.\nA sophisticated wind tunnel that separates feathers, ping pong balls, and baseballs based on how fast they fly.\n\n\n3\nImage Creation\nA computer uses the location (x,y) of the probe and the list of molecules found there to create a map for each molecular weight.\nUsing a list of what sand color was found at each mosaic tile, you create a separate map for ‚Äúall red tiles,‚Äù ‚Äúall blue tiles,‚Äù etc.\n\n\n\n\n\n\nKey Features & Why It‚Äôs Powerful\n\nLabel-Free: You don‚Äôt need dyes or tags to see the molecules. You discover what‚Äôs already there.\nMulti-Target: In a single experiment, you can generate images for hundreds or thousands of different molecules simultaneously.\nSpatially Resolved: It connects chemistry with location. You don‚Äôt just know a drug is in the liver; you know it‚Äôs concentrated in a specific region of a liver lobule.\nVersatile: Works on biological tissues, plants, pharmaceuticals, materials, and even historical artifacts.\n\n\n\n\nTypes of MSI (The Different ‚ÄúProbes‚Äù)\n\nMALDI-MSI: Uses a UV laser to knock molecules off a sample coated with a special matrix. Very common for proteins, peptides, and lipids in biology.\nDESI-MSI: Uses a charged spray of solvent (like a ‚Äúmolecular water jet‚Äù) at ambient pressure. Less damaging, great for drugs and metabolites.\nSIMS-MSI: Uses a beam of high-energy ions for extremely high spatial resolution (down to nanometers), ideal for elements and small molecules on surfaces.\n\n\n\nWhat Do the Results Look Like?\nYou get a gallery of images, each corresponding to a specific molecule. For a brain section, you might see: * Image 1: Distribution of a specific phospholipid (bright in the gray matter). * Image 2: Distribution of a neurotransmitter (bright in specific synaptic regions). * Image 3: Distribution of an administered drug (bright only in the tumor region).\n\n\n\nWhere Is It Used?\n\nDrug Development: Where does a new drug go in an organ? Is it reaching the tumor?\nCancer Research: What are the molecular differences between a tumor‚Äôs core and its edge?\nMetabolomics/Lipidomics: Mapping the complex chemistry of tissues in health and disease.\nToxicology: Where does a toxin accumulate in the liver or kidney?\nMicrobiology: How do molecules distribute in a bacterial colony?\nArt Conservation: Mapping pigments, binders, and degradation products in paintings without taking a sample.\n\nIn a nutshell: MSI is like Google Maps for molecules. Instead of seeing streets and parks, you see the precise location and abundance of chemicals, creating a visual guide to the molecular landscape of almost any surface."
  },
  {
    "objectID": "posts/hyperspectral-imaging.html",
    "href": "posts/hyperspectral-imaging.html",
    "title": "Hyperspectral Imaging Explained",
    "section": "",
    "text": "The ‚ÄúUltra-Specific Color Detective‚Äù\nImagine your eyes (or a regular camera) see the world in only 3 colors: Red, Green, and Blue (RGB). By mixing these, you can create millions of perceived colors, but you can‚Äôt see the specific ‚Äúfingerprint‚Äù of light that makes a leaf, a mineral, or a painted pigment unique.\nHyperspectral Imaging (HSI) doesn‚Äôt just see 3 colors. It sees hundreds of extremely specific, narrow ‚Äúcolors‚Äù (wavelengths) of light, from the visible into the infrared. It captures the full spectral fingerprint of every pixel in an image.\n\n\n\nThe Core Analogy: The Advanced Spy Satellite vs.¬†a Tourist Photo\n\nRGB Camera (Tourist Photo): Takes a picture of a forest. You see green trees, brown soil, and maybe a blue stream. You can guess what things are.\nHyperspectral Imager (Spy Satellite): Takes a picture of the same forest, but for each pixel, it records a detailed light spectrum. It can now identify not just ‚Äúgreen,‚Äù but the exact spectral signature of pine vs.¬†oak, detect stressed vegetation before it turns brown, find camouflaged objects, and identify the mineral composition of the soil. It knows what things are based on their chemistry.\n\n\n\n\nHow It Works: The ‚ÄúData Cube‚Äù\nThis is the key concept. HSI creates a 3D data block called a ‚Äúhypercube.‚Äù\n\nX & Y Axes: These are the spatial dimensions‚Äîjust like a normal picture, they give you the location of each pixel.\nZ Axis (The Magic Dimension): This is the spectral dimension. For each pixel (x,y), instead of just 3 values (R,G,B), you have a full spectrum‚Äîa continuous curve showing how much light is reflected or emitted at hundreds of specific wavelengths.\n\n\nThink of it like this: For every tiny point in the image, you get a miniature graph of its light signature. The camera is essentially a scanner that takes a picture at every single color.\n\n\n\n\nThe Process in 3 Steps\n\n\n\n\n\n\n\n\nStep\nWhat Happens\nSimple Analogy\n\n\n\n\n1. Scan\nThe sensor scans the scene, capturing light not in broad RGB channels, but across hundreds of narrow, adjacent wavelength bands (e.g., every 5 nm from 400 nm to 2500 nm).\nListening to a symphony not with 3 microphones (high, mid, low), but with 200 microphones, each tuned to a specific, narrow musical note.\n\n\n2. Record\nFor each pixel, it records the intensity of light at each wavelength, creating a unique spectral signature or ‚Äúfingerprint.‚Äù\nGetting a detailed barcode for every pixel. A leaf, plastic, and concrete all have wildly different barcodes.\n\n\n3. Analyze & Map\nSpecial software compares these spectral fingerprints to known libraries. It then creates classification maps (e.g., ‚Äúall pixels with the ‚Äòsugar beet leaf‚Äô signature are colored green; all with ‚Äòplastic‚Äô are red‚Äù).\nUsing a barcode scanner on every item in a warehouse to automatically sort them onto different maps.\n\n\n\n\n\n\nKey Superpowers of HSI\n\nSees the Invisible: It uses wavelengths beyond human vision (near-infrared, shortwave-infrared) where materials often have their most distinct signatures.\nNon-Contact & Non-Destructive: You just take a picture from a drone, plane, or in a lab. No touching or sampling needed.\nChemical Mapping: Because the spectral fingerprint is tied to molecular vibrations and electronic transitions, HSI is indirectly mapping chemistry and composition.\nQuantitative: It can measure concentrations (e.g., water content in a leaf, protein in grain).\n\n\n\n\nWhere Is It Used? (Real-World Examples)\n\nPrecision Agriculture & Drones: Detect crop disease weeks before the human eye can, measure water/nutrient stress, and map yield variability from the air.\nEnvironmental Monitoring: Map oil spills on water, identify invasive plant species, monitor mine tailings and soil contamination.\nFood Safety & Quality: Detect fecal contamination on poultry, measure fat/protein content in meat, sort plastics from organic waste in recycling.\nMedical & Surgical Guidance: In the operating room, HSI can visually map oxygen levels in tissue or identify cancerous margins in real-time, helping surgeons remove all the tumor.\nArt Conservation & Forensics: Reveal underdrawings in paintings, identify pigments non-invasively, and detect forged documents or counterfeit goods.\nPlanetary Science & Mining: NASA rovers use HSI to identify minerals on Mars. On Earth, it‚Äôs used for geological mapping and mineral exploration.\n\n\n\n\nHyperspectral vs.¬†Multispectral\n\nMultispectral Imaging: Captures 5-15 broad bands of light (e.g., ‚Äúred,‚Äù ‚Äúnear-infrared‚Äù). It‚Äôs like using a handful of colored filters. Good for specific, known tasks.\nHyperspectral Imaging: Captures 100-300+ very narrow, contiguous bands. It‚Äôs like using a prism to spread light into a full, continuous spectrum for each pixel. Powerful for discovery, identification, and complex analysis."
  }
]